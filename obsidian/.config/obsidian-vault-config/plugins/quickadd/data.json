{
  "choices": [
    {
      "id": "aacec669-cc9c-4d31-a698-17801955c95e",
      "name": "Update Completed Tasks",
      "type": "Macro",
      "command": true,
      "runOnStartup": false,
      "macro": {
        "name": "Update Completed Tasks",
        "id": "fb8e0a7e-a4ef-43fd-8ca3-776a437cf436",
        "commands": [
          {
            "name": "archiveCompletedTasks",
            "type": "UserScript",
            "id": "1255c2bb-7789-415b-bff6-78992a1218d4",
            "path": "10 ðŸ”§ Scripts/archiveCompletedTasks.js",
            "settings": {}
          }
        ]
      }
    }
  ],
  "inputPrompt": "single-line",
  "devMode": false,
  "templateFolderPath": "09 ðŸ“„ Templates",
  "announceUpdates": "all",
  "version": "2.8.0",
  "globalVariables": {},
  "onePageInputEnabled": false,
  "disableOnlineFeatures": true,
  "enableRibbonIcon": false,
  "showCaptureNotification": true,
  "showInputCancellationNotification": false,
  "enableTemplatePropertyTypes": false,
  "ai": {
    "defaultModel": "Ask me",
    "defaultSystemPrompt": "As an AI assistant within Obsidian, your primary goal is to help users manage their ideas and knowledge more effectively. Format your responses using Markdown syntax. Please use the [[Obsidian]] link format. You can write aliases for the links by writing [[Obsidian|the alias after the pipe symbol]]. To use mathematical notation, use LaTeX syntax. LaTeX syntax for larger equations should be on separate lines, surrounded with double dollar signs ($$). You can also inline math expressions by wrapping it in $ symbols. For example, use $$w_{ij}$$ on a separate line, but you can write \"($w_{ij}$)\" inline.",
    "providers": [
      {
        "name": "OpenAI",
        "endpoint": "https://api.openai.com/v1",
        "apiKey": "",
        "models": [
          {
            "name": "text-davinci-003",
            "maxTokens": 4096
          },
          {
            "name": "gpt-3.5-turbo",
            "maxTokens": 4096
          },
          {
            "name": "gpt-3.5-turbo-16k",
            "maxTokens": 16384
          },
          {
            "name": "gpt-3.5-turbo-1106",
            "maxTokens": 16385
          },
          {
            "name": "gpt-4",
            "maxTokens": 8192
          },
          {
            "name": "gpt-4-32k",
            "maxTokens": 32768
          },
          {
            "name": "gpt-4-1106-preview",
            "maxTokens": 128000
          },
          {
            "name": "gpt-4-turbo",
            "maxTokens": 128000
          },
          {
            "name": "gpt-4o",
            "maxTokens": 128000
          },
          {
            "name": "gpt-4o-mini",
            "maxTokens": 128000
          }
        ],
        "autoSyncModels": false,
        "modelSource": "modelsDev"
      },
      {
        "name": "Gemini",
        "endpoint": "https://generativelanguage.googleapis.com",
        "apiKey": "",
        "models": [
          {
            "name": "gemini-1.5-pro",
            "maxTokens": 1000000
          },
          {
            "name": "gemini-1.5-flash",
            "maxTokens": 1000000
          },
          {
            "name": "gemini-1.5-flash-8b",
            "maxTokens": 1000000
          }
        ],
        "autoSyncModels": false,
        "modelSource": "modelsDev"
      }
    ]
  },
  "migrations": {
    "migrateToMacroIDFromEmbeddedMacro": true,
    "useQuickAddTemplateFolder": true,
    "incrementFileNameSettingMoveToDefaultBehavior": true,
    "mutualExclusionInsertAfterAndWriteToBottomOfFile": true,
    "setVersionAfterUpdateModalRelease": true,
    "addDefaultAIProviders": true,
    "removeMacroIndirection": true,
    "migrateFileOpeningSettings": true,
    "setProviderModelDiscoveryMode": true
  }
}